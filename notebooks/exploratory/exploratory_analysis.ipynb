{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitkeep', 'aptos2019-blindness-detection.zip', 'sample_submission.csv', 'test.csv', 'test_images', 'test_images.zip', 'train.csv', 'train_images', 'train_images.zip']\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = '../../data/raw'\n",
    "print(os.listdir(BASE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasets for the model construction\n",
    "train = pd.read_csv(os.path.join(BASE_PATH,'train.csv'))\n",
    "test = pd.read_csv(os.path.join(BASE_PATH,'test.csv'))\n",
    "submit = pd.read_csv(os.path.join(BASE_PATH,'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset shape is :  (3662, 2)\n",
      "The testing dataset shape is  :  (1928, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display the size of the train and test datasets.\n",
    "print('The training dataset shape is : ',train.shape)\n",
    "print('The testing dataset shape is  : ',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset information: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3662 entries, 0 to 3661\n",
      "Data columns (total 2 columns):\n",
      "id_code      3662 non-null object\n",
      "diagnosis    3662 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 57.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display some basic information from the dataset.\n",
    "print('Train dataset information:', '\\n')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
